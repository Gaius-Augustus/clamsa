import gzip
import re
import random
import numpy as np
import tensorflow as tf
from Bio import SeqIO
import sys
import math
from contextlib import ExitStack
import time
from tqdm import tqdm





def reverse_complement(seq, alphabet="acgt"):
    """ Reverse complement function to obtain minus strand sequences
    Args:
        seq (str): Sequence in the given alphabet
        alphabet (str): All characters of the wanted alphabet in precise order
        
    Returns:
        str: Modification of the inverse of the input sequence. Each character in the input sequence is replaced with its complement in the given alphabet. Here the complement of the `i`-th letter in an alphabet of `n` characters is the `n-i`-th character.
    """
    return seq[::-1].translate( str.maketrans(alphabet, alphabet[::-1]) )




def import_augustus_training_file(path, undersample_neg_by_factor = 1., alphabet=['a', 'c', 'g', 't']):
    """ Imports the training files generated by augustus. This method is tied to the specific
     implementation of GeneMSA::getAllOEMsas and GeneMSA::getMsa.
     
    Args:
        path (str): Location of the file generated by augustus (typically denoted *.out or *.out.gz)
        undersample_neg_by_factor (float): take any negative sample only with probability 1 / undersample_neg_by_factor, set to 1.0 to use all negative examples
        alphabet (List[str]): Alphabet in which the sequences are written
    
    Returns:
        List[dict]: Training examples read from the file. Each example is represented
                    by a `dict` of the form
                    {
                        'y' (int): Model ID. Where 0 represents non-coding region and 1 represents coding region
                        'cid' (str): Chromosome ID
                        'start_idx' (int): Start index of the MSA in the full alignment
                        'end_idx' (int): End index of the MSA in the full alignment
                        'is_on_plus_strand' (bool): Whether the MSA is written on the plus strand
                        'frame' (int): Number in [0,1,2] representing the reading frame of codons.
                        'spec_ids' (List[int]): IDs of the aligned species in the given entry.
                        'offsets' (List[int]): Offsets of the start indices in the DNA of the respective species.
                        'seq' (List[List[str]]): Raw MSA read from the file.
                        'S' (numpy.array): MSA converted to a matrix of integers, each representing the index of the character in the given alphabet.
                    }
        int: Number of unique species encountered in the file.
    
    """
    
    
    # entries already read
    training_data = []
    
    # counts number of unique species encountered the file
    num_species = 0
    
    # translation between alphabet and indices in the alphabet
    # {'a': 0, 'c': 1, 'g': 2, 't': 3}
    alpha_indices = dict(zip(alphabet, range(len(alphabet))))
    
    
    with gzip.open(path, 'rt') if path.endswith('.gz') else open(path, 'r') as f:
        
        # Regex Pattern recognizing lines generated by GeneMSA::getMsa
        slice_pattern = re.compile("^[0-9]+\\t[0-9]+\\t\\t[acgt\-]+")
        
        # whether the current sequence should be skipped due to 
        # a undersample roll
        skip_entry = False
        
        for line in f:
            
            # parse the lines generated by GeneMSA::getAllOEMsas
            if line.startswith("y="):
                
                # decide whether the upcoming entry should be skipped
                skip_entry = line[2]=='0' and random.random() > 1. / undersample_neg_by_factor
                
                if skip_entry:
                    continue
                
                oe_data = line.split("\t")
                y = int(oe_data[0][2])
                cid = oe_data[2]
                start_idx = int(oe_data[3])
                end_idx = int(oe_data[4])
                is_on_plus_strand = (oe_data[5] == "+")
                frame = int(oe_data[6][0])
                
                
                training_data.append({
                    "y" : y,
                    "cid" : cid,
                    "start_idx" : start_idx,
                    "end_idx" : end_idx,
                    "is_on_plus_strand" : is_on_plus_strand,
                    "frame" : frame,
                    "spec_ids" : [],
                    "offsets" : [],
                    "seq" : [], # a, c, g, t, n, -
                    "S" : [],   # 0, 1, 2, 3
                })
            
            # parse the lines generated by GeneMSA::getMsa
            elif slice_pattern.match(line) and not skip_entry:
                slice_data = line.split("\t")
                specid = int(slice_data[0])
                offset = int(slice_data[1])
                seq = slice_data[3][:-1]
                if not is_on_plus_strand:
                    seq = reverse_complement(seq)             
                
                # convert characters to indices in the given alphabet
                seq_numbers = np.full(len(seq), None) # any unkown character is None and treated as missing data later
                
                for i in range(len(seq)):
                    if seq[i] in alpha_indices:
                        seq_numbers[i] = alpha_indices[seq[i]] # convert a to 0, c to 1, etc
                
                training_data[-1]["spec_ids"].append(specid)
                training_data[-1]["offsets"].append(offset)
                training_data[-1]["seq"].append(seq)
                training_data[-1]["S"].append(seq_numbers)
                
            # retrieve the number of species
            elif line.startswith("species ") and not skip_entry:
                specid = int(line[8:].split("\t")[0])
                num_species = max(num_species, specid + 1)
    # convert the sequences to numpy arrays
    for i in range(len(training_data)):
        training_data[i]["S"] = np.array(training_data[i]["S"])

    return training_data, num_species



# TODO: Testen sobald Daten vorhanden
def import_phylocsf_training_file(dir, species = ["droMoj", "droVir", "droGri", "dm", "droSim", "droSec", "droEre", "droYak", "droAna", "droPse", "droPer", "droWil"]):
    """ Imports the alignments referenced in the PhyloCSF paper: LDRK_alignments_multiz12.zip unpacked

    Args:
        dir (str): Path to the unpacked LDRK_alignments_multiz12.zip folder with subfolders `controls` and `exons`
        species (List[str]): Species to encounter in the dataset
    
    Returns:
        List[dict]: Training examples read from the file. Each example is represented
                    by a `dict` of the form
                    {
                        'y' (int): Model ID. Where 0 represents non-coding region and 1 represents coding region
                        'cid' (str): Chromosome ID
                        'start_idx' (int): Start index of the MSA in the full alignment
                        'end_idx' (int): End index of the MSA in the full alignment
                        'is_on_plus_strand' (bool): Whether the MSA is written on the plus strand
                        'frame' (int): Number in [0,1,2] representing the reading frame of codons.
                        'spec_ids' (List[int]): IDs of the aligned species in the given entry.
                        'offsets' (List[int]): Offsets of the start indices in the DNA of the respective species.
                        'seq' (List[List[str]]): Raw MSA read from the file.
                        'S' (numpy.array): MSA converted to a matrix of integers, each representing the index of the character in the given alphabet.
                    }
        int: Number of unique species encountered in the files.
    
    """
    training_data = []
    num_species = len(species)
    ignore = False

    classdirnames = ["controls", "exons"] # subdirectories of dir
    for y in range(2):
        basedir = dir + "/" + classdirnames[y]
        print ("basedir=", basedir)
        for root, dirs, files in os.walk(basedir, topdown = True):
            for fname in files:
                if fname[-4:] == ".mfa":
                    fullname = root + "/" +fname

                    if numExamples <= 0:
                        break
                    
                    if y == 0 and random.random() > 1. / undersample_neg_by_factor:
                        continue
                    numExamples -= 1
                    
                    for i, record in enumerate(SeqIO.parse(fullname, "fasta")):
                        seq = str(record.seq).lower()
                        if i == 0: # reference species
                            header_fields = record.id.split("|")
                            assert header_fields[0] == "dm", "reference species is not dm"
                            species_idx = species.index("dm")
                            is_on_plus_strand = True if len(header_fields) < 5 or header_fields[4] != 'revcomp' else False
                            frame = int(header_fields[2][-1])
                            training_data.append({
                                "y" : y,
                                "is_on_plus_strand" : is_on_plus_strand,
                                "frame" : frame,
                                "spec_ids" : [species_idx],
                                "seq" : [seq], # a, c, g, t, n, -
                                "S" : [encode_seq(seq)],   # 0, 1, 2, 3
                            })
                        else:
                            species_idx = phyloCSFspecies.index(record.id)
                            training_data[-1]["spec_ids"].append(species_idx)
                            training_data[-1]["seq"].append(seq)
                            training_data[-1]["S"].append(encode_seq(seq))
                            
    # convert the sequences to numpy arrays
    for i in range(len(training_data)):
        training_data[i]["S"] = np.array(training_data[i]["S"])

    return training_data, num_species






def write_example(imodel, num_species, iconfigurations, leaf_configuration, tfwriter, should_debug = False):
    """Write one-hot encoded MSA as an entry into a  Tensorflow-Records file.
    
    Args:
        imodel (int): Model ID. In our convention: 0 - non-coding region, 1 - coding region
        num_species (int): Total number of species
        iconfiguration (List[int]): Indices of species occuring in the MSA.
        leaf_configuration (numpy.array): MSA
        tfwriter (TFRecordWriter): Target to which the example shall be written.
    """
    
    # Infer the length of the sequence
    sequence_length = leaf_configuration.shape[1]
    
    
    # one-hot encoding of characters
    leaf_onehot = np.ones((num_species, sequence_length, s), dtype = np.int32)
    leaf_onehot[iconfigurations, ...] = \
        ((np.arange(s) == leaf_configuration[:, :, None]) | # an actual codon
         (None == leaf_configuration[:, :, None]) # contains at least one unknown character
        ).astype(int)
    p_leaf_onehot = leaf_onehot.tostring()

    if should_debug:
        np.set_printoptions(threshold = np.inf)
        print(f"model: {imodel}")
        print(f"iconfiguration: {iconfigurations}")
        print(f"sequence_length: {sequence_length}")
        print(f"leaf_onehot.shape: {leaf_onehot.shape}")
        print(f"leaf_onehot[iconfigurations[1],...]: {leaf_onehot[iconfigurations[1], ...]}")

    # TODO loeschen
    iconfigurations = np.arange(num_species).tolist()

    # put the bytes in context_list and feature_list
    ## save imodel and iconfigurations in context list 
    context_lists = tf.train.Features(feature = {
        'model': tf.train.Feature(int64_list = tf.train.Int64List(value = [imodel])),
        'configurations': tf.train.Feature(int64_list = tf.train.Int64List(value = iconfigurations)),
        'sequence_length': tf.train.Feature(int64_list = tf.train.Int64List(value = [sequence_length])),
    })

    ## save p_leaf_onehot as a one element sequence in feature_lists
    leaf_onehot_list_pickle = [tf.train.Feature(bytes_list = tf.train.BytesList(value = [p_leaf_onehot]))]

    feature_lists = tf.train.FeatureLists(feature_list = {
        'sequence_onehot': tf.train.FeatureList(feature = leaf_onehot_list_pickle)
    })

    # create the SequenceExample
    SeqEx = tf.train.SequenceExample(
        context = context_lists,
        feature_lists = feature_lists
        )
    SeqEx_serialized = SeqEx.SerializeToString()

    tfwriter.write(SeqEx_serialized)

    
    
def persist_as_tfrecord(out_dir, splits, use_codons=False, use_compression=True, verbose=False):
    print("test")
