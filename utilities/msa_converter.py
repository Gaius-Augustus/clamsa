import gzip
import re
import random
import numpy as np
import tensorflow as tf
from Bio import SeqIO
import sys
import math
from contextlib import ExitStack
import time
from tqdm import tqdm


class MSA(object):
    def __init__(self, model = None, chromosome_id = None, start_index = None, end_index = None, is_on_plus_strand = False, frame = 0, spec_ids = [], offsets = [], sequence = []):
        self.model = model
        self.chromosome_id = chromosome_id
        self.start_index = start_index
        self.end_index = end_index
        self.is_on_plus_strand = is_on_plus_strand
        self.frame = frame
        self.spec_ids = spec_ids
        self.offsets = offsets
        self.sequence = sequence
        self._updated_sequence = True
        self._coded_sequence = None

    @property
    def coded_sequence(self, alphabet="acgt"):

        # Lazy loading
        if not self._updated_sequence:
            return self._coded_sequence

        # whether the sequences and coding alphabet shall be flipped
        inv_coef = -1 if not self.is_on_plus_strand else 1

        # translated alphabet as indices of (inversed) alphabet
        translated_alphabet = dict(zip( alphabet, range(len(alphabet))[::inv_coef] ))

        # view the sequence as a numpy array
        ca = np.array([list(S[::inv_coef]) for S in self.sequence])

        # translate the list of sequences and convert it to a numpy matrix
        # non-alphabet characters are replaced by -1
        self._coded_sequence = np.vectorize(lambda c: translated_alphabet.get(c, -1))(ca)

        # Update lazy loading
        self._updated_sequence = False


        return self._coded_sequence

    @property
    def sequence(self):
        return self._sequence
    @sequence.setter
    def sequence(self, value):
        self._sequence = value
        self._updated_sequence = True

    def __str__(self):
        return f"{{\n\tmodel: {self.model},\n\tchromosome_id: {self.chromosome_id},\n\tstart_index: {self.start_index},\n\tend_index: {self.end_index},\n\tis_on_plus_strand: {self.is_on_plus_strand},\n\tframe: {self.frame},\n\tspec_ids: {self.spec_ids},\n\toffsets: {self.offsets},\n\tsequence: {self.sequence},\n\tcoded_sequence: {self.coded_sequence}\n}}"
    


def reverse_complement(seq, alphabet="acgt"):
    """ Reverse complement function to obtain minus strand sequences
    Args:
        seq (str): Sequence in the given alphabet
        alphabet (str): All characters of the wanted alphabet in precise order
        
    Returns:
        str: Modification of the inverse of the input sequence. Each character in the input sequence is replaced with its complement in the given alphabet. Here the complement of the `i`-th letter in an alphabet of `n` characters is the `n-i`-th character.
    """
    return seq[::-1].translate( str.maketrans(alphabet, alphabet[::-1]) )




def import_augustus_training_file(path, undersample_neg_by_factor = 1., alphabet=['a', 'c', 'g', 't']):
    """ Imports the training files generated by augustus. This method is tied to the specific
     implementation of GeneMSA::getAllOEMsas and GeneMSA::getMsa.
     
    Args:
        path (str): Location of the file generated by augustus (typically denoted *.out or *.out.gz)
        undersample_neg_by_factor (float): take any negative sample only with probability 1 / undersample_neg_by_factor, set to 1.0 to use all negative examples
        alphabet (List[str]): Alphabet in which the sequences are written
    
    Returns:
        List[dict]: Training examples read from the file. Each example is represented
                    by a `dict` of the form
                    {
                        'y' (int): Model ID. Where 0 represents non-coding region and 1 represents coding region
                        'cid' (str): Chromosome ID
                        'start_idx' (int): Start index of the MSA in the full alignment
                        'end_idx' (int): End index of the MSA in the full alignment
                        'is_on_plus_strand' (bool): Whether the MSA is written on the plus strand
                        'frame' (int): Number in [0,1,2] representing the reading frame of codons.
                        'spec_ids' (List[int]): IDs of the aligned species in the given entry.
                        'offsets' (List[int]): Offsets of the start indices in the DNA of the respective species.
                        'seq' (List[List[str]]): Raw MSA read from the file.
                        'S' (numpy.array): MSA converted to a matrix of integers, each representing the index of the character in the given alphabet.
                    }
        int: Number of unique species encountered in the file.
    
    """
    
    
    # entries already read
    training_data = []
    
    # counts number of unique species encountered the file
    num_species = 0
    
    # translation between alphabet and indices in the alphabet
    # {'a': 0, 'c': 1, 'g': 2, 't': 3}
    alpha_indices = dict(zip(alphabet, range(len(alphabet))))
    
    
    with gzip.open(path, 'rt') if path.endswith('.gz') else open(path, 'r') as f:
        
        # Regex Pattern recognizing lines generated by GeneMSA::getMsa
        slice_pattern = re.compile("^[0-9]+\\t[0-9]+\\t\\t[acgt\-]+")
        
        # whether the current sequence should be skipped due to 
        # a undersample roll
        skip_entry = False
        
        for line in f:
            
            # parse the lines generated by GeneMSA::getAllOEMsas
            if line.startswith("y="):
                
                # decide whether the upcoming entry should be skipped
                skip_entry = line[2]=='0' and random.random() > 1. / undersample_neg_by_factor
                
                if skip_entry:
                    continue
                
                oe_data = line.split("\t")
                
                msa = MSA(
                        model = int(oe_data[0][2]),
                        chromosome_id = oe_data[2], 
                        start_index = int(oe_data[3]),
                        end_index = int(oe_data[4]),
                        is_on_plus_strand = (oe_data[5] == '+'),
                        frame = int(oe_data[6][0]),
                        spec_ids = [],
                        offsets = [],
                        sequence = []
                )
                
                training_data.append(msa)
            
            # parse the lines generated by GeneMSA::getMsa
            elif slice_pattern.match(line) and not skip_entry:
                slice_data = line.split("\t")
                entry = training_data[-1]

                entry.spec_ids.append(int(slice_data[0]))
                entry.offsets.append(int(slice_data[1]))
                entry.sequence.append(slice_data[3][:-1])

                
            # retrieve the number of species
            elif line.startswith("species ") and not skip_entry:
                specid = int(line[8:].split("\t")[0])
                num_species = max(num_species, specid + 1)

    return training_data, num_species



# TODO: Testen sobald Daten vorhanden
def import_phylocsf_training_file(dir, species = ["droMoj", "droVir", "droGri", "dm", "droSim", "droSec", "droEre", "droYak", "droAna", "droPse", "droPer", "droWil"]):
    """ Imports the alignments referenced in the PhyloCSF paper: LDRK_alignments_multiz12.zip unpacked

    Args:
        dir (str): Path to the unpacked LDRK_alignments_multiz12.zip folder with subfolders `controls` and `exons`
        species (List[str]): Species to encounter in the dataset
    
    Returns:
        List[dict]: Training examples read from the file. Each example is represented
                    by a `dict` of the form
                    {
                        'y' (int): Model ID. Where 0 represents non-coding region and 1 represents coding region
                        'cid' (str): Chromosome ID
                        'start_idx' (int): Start index of the MSA in the full alignment
                        'end_idx' (int): End index of the MSA in the full alignment
                        'is_on_plus_strand' (bool): Whether the MSA is written on the plus strand
                        'frame' (int): Number in [0,1,2] representing the reading frame of codons.
                        'spec_ids' (List[int]): IDs of the aligned species in the given entry.
                        'offsets' (List[int]): Offsets of the start indices in the DNA of the respective species.
                        'seq' (List[List[str]]): Raw MSA read from the file.
                        'S' (numpy.array): MSA converted to a matrix of integers, each representing the index of the character in the given alphabet.
                    }
        int: Number of unique species encountered in the files.
    
    """
    training_data = []
    num_species = len(species)
    ignore = False

    classdirnames = ["controls", "exons"] # subdirectories of dir
    for y in range(2):
        basedir = dir + "/" + classdirnames[y]
        print ("basedir=", basedir)
        for root, dirs, files in os.walk(basedir, topdown = True):
            for fname in files:
                if fname[-4:] == ".mfa":
                    fullname = root + "/" +fname

                    if numExamples <= 0:
                        break
                    
                    if y == 0 and random.random() > 1. / undersample_neg_by_factor:
                        continue
                    numExamples -= 1
                    
                    for i, record in enumerate(SeqIO.parse(fullname, "fasta")):
                        seq = str(record.seq).lower()
                        if i == 0: # reference species
                            header_fields = record.id.split("|")
                            assert header_fields[0] == "dm", "reference species is not dm"
                            species_idx = species.index("dm")
                            is_on_plus_strand = True if len(header_fields) < 5 or header_fields[4] != 'revcomp' else False
                            frame = int(header_fields[2][-1])
                            training_data.append({
                                "y" : y,
                                "is_on_plus_strand" : is_on_plus_strand,
                                "frame" : frame,
                                "spec_ids" : [species_idx],
                                "seq" : [seq], # a, c, g, t, n, -
                                "S" : [encode_seq(seq)],   # 0, 1, 2, 3
                            })
                        else:
                            species_idx = phyloCSFspecies.index(record.id)
                            training_data[-1]["spec_ids"].append(species_idx)
                            training_data[-1]["seq"].append(seq)
                            training_data[-1]["S"].append(encode_seq(seq))
                            
    # convert the sequences to numpy arrays
    for i in range(len(training_data)):
        training_data[i]["S"] = np.array(training_data[i]["S"])

    return training_data, num_species






def write_example(imodel, num_species, iconfigurations, leaf_configuration, tfwriter, should_debug = False):
    """Write one-hot encoded MSA as an entry into a  Tensorflow-Records file.
    
    Args:
        imodel (int): Model ID. In our convention: 0 - non-coding region, 1 - coding region
        num_species (int): Total number of species
        iconfiguration (List[int]): Indices of species occuring in the MSA.
        leaf_configuration (numpy.array): MSA
        tfwriter (TFRecordWriter): Target to which the example shall be written.
    """
    
    # Infer the length of the sequence
    sequence_length = leaf_configuration.shape[1]
    
    
    # one-hot encoding of characters
    leaf_onehot = np.ones((num_species, sequence_length, s), dtype = np.int32)
    leaf_onehot[iconfigurations, ...] = \
        ((np.arange(s) == leaf_configuration[:, :, None]) | # an actual codon
         (None == leaf_configuration[:, :, None]) # contains at least one unknown character
        ).astype(int)
    p_leaf_onehot = leaf_onehot.tostring()

    if should_debug:
        np.set_printoptions(threshold = np.inf)
        print(f"model: {imodel}")
        print(f"iconfiguration: {iconfigurations}")
        print(f"sequence_length: {sequence_length}")
        print(f"leaf_onehot.shape: {leaf_onehot.shape}")
        print(f"leaf_onehot[iconfigurations[1],...]: {leaf_onehot[iconfigurations[1], ...]}")

    # TODO loeschen
    iconfigurations = np.arange(num_species).tolist()

    # put the bytes in context_list and feature_list
    ## save imodel and iconfigurations in context list 
    context_lists = tf.train.Features(feature = {
        'model': tf.train.Feature(int64_list = tf.train.Int64List(value = [imodel])),
        'configurations': tf.train.Feature(int64_list = tf.train.Int64List(value = iconfigurations)),
        'sequence_length': tf.train.Feature(int64_list = tf.train.Int64List(value = [sequence_length])),
    })

    ## save p_leaf_onehot as a one element sequence in feature_lists
    leaf_onehot_list_pickle = [tf.train.Feature(bytes_list = tf.train.BytesList(value = [p_leaf_onehot]))]

    feature_lists = tf.train.FeatureLists(feature_list = {
        'sequence_onehot': tf.train.FeatureList(feature = leaf_onehot_list_pickle)
    })

    # create the SequenceExample
    SeqEx = tf.train.SequenceExample(
        context = context_lists,
        feature_lists = feature_lists
        )
    SeqEx_serialized = SeqEx.SerializeToString()

    tfwriter.write(SeqEx_serialized)

    
    
def persist_as_tfrecord(out_dir, dataset, splits=None, split_models=None, use_codons=False, use_compression=True, verbose=False):
    models = [""]
    if split_by_model:
        models = [0, 1]
    
    notify_frequency = max(1, int(0.1 * num_ex))

    options = tf.io.TFRecordOptions(compression_type = 'GZIP')

    with ExitStack() as stack:
        ss = [4, 64] if use_codons else [4]
    
        tfwriters = [[[None] * len(models) for j in range(len(split_names))] for k in ss]
        
        for r, s in enumerate(ss):
            for j, p in enumerate(split_names):
                for model in models:
                    tfwriters[r][j][model] = \
                        stack.enter_context(tf.io.TFRecordWriter(f"{outfile_prefix}s{s}-{p}-y{model}.tfrecord.gz",
                                                                 options = options))

        for i in range(num_ex):
            if T[i]["S"].shape[0] < 2 or pmap[i] < 0:
                continue
            # context features to be saved
            iconfigurations = T[i]["spec_ids"]
            
            for r, s in enumerate(ss):
                # character indices written in the leaves of the i-th sequence
                if (r == 0):
                    leaf_configuration = T[i]["S"]
                else:
                    leaf_configuration = T[i]["CS"]
                    
                sequence_length = leaf_configuration.shape[1] # length of the sequence

                if sequence_length > max_sequence_length or sequence_length < min_sequence_length:
                    continue
                
                imodel = T[i]["y"] if split_by_model else 0 
                k = 0
                
                tfwriter = tfwriters[r][pmap[i]][imodel]

                should_debug = (i < 0)
                write_example(imodel, iconfigurations, leaf_configuration, sequence_length, tfwriter, should_debug = should_debug)
                
            if verbose:
                print(f"leaf_configuration[1,...]: {leaf_configuration.shape} {leaf_configuration[1,...]}")
                ichar_test = np.random.randint(0, sequence_length)
                print("ichar_test:", ichar_test)
                print(f"Sample of the conversion:")
                print(f"\tModel: {imodel}")
                print(f"\tSequence Length: {sequence_length}")
                print(f"\tConfiguration: {iconfigurations}")
                print(f"\tPosition {ichar_test} character of the sequence: {leaf_configuration[:, ichar_test]}")
                print(num_species)

            if i % notify_frequency == 0 or i+1 == num_ex:
                    print(f"{i / num_ex * 100 : .2f}%")
